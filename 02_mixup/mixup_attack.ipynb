{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "mixup_attack.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21d53b92e94b4d7ab628ef44cdc5e4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6e6326d212e44134a70b9280cd3ceb7a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1dff0f7ada7b464fa7ebb16d0d137b19",
              "IPY_MODEL_96dcf3068a224f7cb36659a28c0ea846"
            ]
          }
        },
        "6e6326d212e44134a70b9280cd3ceb7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1dff0f7ada7b464fa7ebb16d0d137b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba2859fc16a9460d96ff67c7a4fdbee0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38fab719bf7a47758b4fbe9a8b08eca6"
          }
        },
        "96dcf3068a224f7cb36659a28c0ea846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_04e2a6b6cdf94842a097babf7d5aa527",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:30, 13850380.09it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0472fce805ea477196109583019d1761"
          }
        },
        "ba2859fc16a9460d96ff67c7a4fdbee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38fab719bf7a47758b4fbe9a8b08eca6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04e2a6b6cdf94842a097babf7d5aa527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0472fce805ea477196109583019d1761": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wielandbrendel/robustness_workshop/blob/master/02_mixup/mixup_attack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAqa1klSrkEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "ae9c0d2b-e288-449b-c406-532c669c1696"
      },
      "source": [
        "# this cell contains all the commands necessary to run this notebook in colab\n",
        "# if you cloned the repository and run this notebook locally you do not need to run these commands\n",
        "!wget https://raw.githubusercontent.com/wielandbrendel/robustness_workshop/master/02_mixup/resnet_3layer.py\n",
        "!wget https://raw.githubusercontent.com/wielandbrendel/robustness_workshop/master/02_mixup/transforms.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-16 21:19:04--  https://raw.githubusercontent.com/wielandbrendel/robustness_workshop/master/02_mixup/resnet_3layer.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10735 (10K) [text/plain]\n",
            "Saving to: ‘resnet_3layer.py’\n",
            "\n",
            "\rresnet_3layer.py      0%[                    ]       0  --.-KB/s               \rresnet_3layer.py    100%[===================>]  10.48K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-16 21:19:05 (96.5 MB/s) - ‘resnet_3layer.py’ saved [10735/10735]\n",
            "\n",
            "--2020-02-16 21:19:07--  https://raw.githubusercontent.com/wielandbrendel/robustness_workshop/master/02_mixup/transforms.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2865 (2.8K) [text/plain]\n",
            "Saving to: ‘transforms.py’\n",
            "\n",
            "transforms.py       100%[===================>]   2.80K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-16 21:19:07 (55.4 MB/s) - ‘transforms.py’ saved [2865/2865]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fL2rST3QrzuT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "4d1877bf-e47e-44c8-e2d9-c7428a1e117a"
      },
      "source": [
        "# run this cell the first time you execute this notebook to download the pretrained weights\n",
        "!wget https://github.com/wielandbrendel/robustness_workshop/releases/download/v0.0.1/mixup_model_IAT.ckpt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-16 21:19:11--  https://github.com/wielandbrendel/robustness_workshop/releases/download/v0.0.1/mixup_model_IAT.ckpt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/240598071/fcd8f180-4f77-11ea-869e-ca69549353a8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200216%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200216T211912Z&X-Amz-Expires=300&X-Amz-Signature=aa924e78211081bad2b196573032ee4f9b1d4135c5be3db695249b4ea7e157f4&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmixup_model_IAT.ckpt&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-02-16 21:19:12--  https://github-production-release-asset-2e65be.s3.amazonaws.com/240598071/fcd8f180-4f77-11ea-869e-ca69549353a8?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200216%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200216T211912Z&X-Amz-Expires=300&X-Amz-Signature=aa924e78211081bad2b196573032ee4f9b1d4135c5be3db695249b4ea7e157f4&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dmixup_model_IAT.ckpt&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.132.59\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.132.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19119341 (18M) [application/octet-stream]\n",
            "Saving to: ‘mixup_model_IAT.ckpt’\n",
            "\n",
            "mixup_model_IAT.ckp 100%[===================>]  18.23M  6.44MB/s    in 2.8s    \n",
            "\n",
            "2020-02-16 21:19:16 (6.44 MB/s) - ‘mixup_model_IAT.ckpt’ saved [19119341/19119341]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE_3ky-Rrd2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "5ab6c3b8-0125-4c2c-99cd-e362e7b4b70c"
      },
      "source": [
        "# install the latest master version of Foolbox 3.0\n",
        "!pip3 install git+https://github.com/bethgelab/foolbox.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/bethgelab/foolbox.git\n",
            "  Cloning https://github.com/bethgelab/foolbox.git to /tmp/pip-req-build-haim7_5b\n",
            "  Running command git clone -q https://github.com/bethgelab/foolbox.git /tmp/pip-req-build-haim7_5b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from foolbox==3.0.0b0) (1.4.1)\n",
            "Collecting typing-extensions>=3.7.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/03/92/705fe8aca27678e01bbdd7738173b8e7df0088a2202c80352f664630d638/typing_extensions-3.7.4.1-py3-none-any.whl\n",
            "Collecting GitPython>=3.0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d2/5b44bbfea118bd97d94549b8a0eb2fd60e619c8fdeead4fa7cf666738cbd/GitPython-3.0.7-py3-none-any.whl (451kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 30.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from foolbox==3.0.0b0) (45.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from foolbox==3.0.0b0) (1.17.5)\n",
            "Collecting eagerpy==0.25.2\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/fa/8d52cefda0d21b7262a18d745f5d6e07e035093118947b070eb4ca449557/eagerpy-0.25.2-py3-none-any.whl\n",
            "Collecting gitdb2>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/5e/4ec98f192bbf783917c0d68f23fb588a8f394fed67b90197786bdb30d0c7/gitdb2-3.0.0-py2.py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 13.0MB/s \n",
            "\u001b[?25hCollecting smmap2>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: foolbox\n",
            "  Building wheel for foolbox (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for foolbox: filename=foolbox-3.0.0b0-cp36-none-any.whl size=1646382 sha256=0c1b4777a08dee7db1ef44d58c08ee087293ee9756137c314a85c3af9b7f93bb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u5i1ksz9/wheels/8e/a2/bb/f8c32a40c4c24a1964bad2e096cb35eaf44a5e6349aab26957\n",
            "Successfully built foolbox\n",
            "\u001b[31mERROR: chainer 6.5.0 has requirement typing-extensions<=3.6.6, but you'll have typing-extensions 3.7.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: typing-extensions, smmap2, gitdb2, GitPython, eagerpy, foolbox\n",
            "  Found existing installation: typing-extensions 3.6.6\n",
            "    Uninstalling typing-extensions-3.6.6:\n",
            "      Successfully uninstalled typing-extensions-3.6.6\n",
            "Successfully installed GitPython-3.0.7 eagerpy-0.25.2 foolbox-3.0.0b0 gitdb2-3.0.0 smmap2-2.0.5 typing-extensions-3.7.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqxWRcswvCnC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d332f4c1-ab19-4f2d-bc9a-d2c9c42f5f11"
      },
      "source": [
        "!pip3 install --upgrade typing_extensions"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: typing_extensions in /usr/local/lib/python3.6/dist-packages (3.7.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTiLRzJ_rYA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import foolbox as fb\n",
        "import eagerpy as ep\n",
        "\n",
        "import transforms\n",
        "import resnet_3layer as resnet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TDsX2H2rYBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_sample_MIOL = 15\n",
        "lamdaOL = 0.6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR5LcewzrYBc",
        "colab_type": "text"
      },
      "source": [
        "### Load backbone model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do8LodSorYBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSIFIER = resnet.model_dict['resnet50']\n",
        "classifier = CLASSIFIER(num_classes=10)\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "classifier = classifier.to(device)\n",
        "\n",
        "classifier.load_state_dict(torch.load('mixup_model_IAT.ckpt'))\n",
        "classifier.eval();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onppDLrirYBo",
        "colab_type": "text"
      },
      "source": [
        "### Construct image pools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd7GM1_BrYBs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "21d53b92e94b4d7ab628ef44cdc5e4ae",
            "6e6326d212e44134a70b9280cd3ceb7a",
            "1dff0f7ada7b464fa7ebb16d0d137b19",
            "96dcf3068a224f7cb36659a28c0ea846",
            "ba2859fc16a9460d96ff67c7a4fdbee0",
            "38fab719bf7a47758b4fbe9a8b08eca6",
            "04e2a6b6cdf94842a097babf7d5aa527",
            "0472fce805ea477196109583019d1761"
          ]
        },
        "outputId": "860a63f8-8d11-4a07-9f3f-537acb1654a0"
      },
      "source": [
        "def onehot(ind):\n",
        "    vector = np.zeros([10])\n",
        "    vector[ind] = 1\n",
        "    return vector.astype(np.float32)\n",
        "\n",
        "train_trans, test_trans = transforms.cifar_transform()\n",
        "trainset = torchvision.datasets.CIFAR10(root='~/cifar/',\n",
        "                                        train=False,\n",
        "                                        download=True,\n",
        "                                        transform=train_trans,\n",
        "                                        target_transform=onehot)\n",
        "testset = torchvision.datasets.CIFAR10(root='~/cifar/',\n",
        "                                       train=False,\n",
        "                                       download=True,\n",
        "                                       transform=test_trans,\n",
        "                                       target_transform=onehot)\n",
        "\n",
        "# we reduce the testset for this workshop\n",
        "testset.data = testset.data[:200]\n",
        "\n",
        "dataloader_train = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    num_workers=2)\n",
        "\n",
        "dataloader_test = torch.utils.data.DataLoader(\n",
        "    testset,\n",
        "    batch_size=10,\n",
        "    shuffle=False,\n",
        "    num_workers=5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /root/cifar/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21d53b92e94b4d7ab628ef44cdc5e4ae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/cifar/cifar-10-python.tar.gz to /root/cifar/\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3sBHEl2DrYB1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bfec3f5a-257c-4f92-a7fa-95a43da7e4fd"
      },
      "source": [
        "from tqdm import tqdm\n",
        "num_pool = 10000\n",
        "mixup_pool_OL = {}\n",
        "\n",
        "for i in range(10):\n",
        "    mixup_pool_OL.update({i: []})\n",
        "\n",
        "for i, data_batch in tqdm(enumerate(dataloader_train), total=num_pool):\n",
        "    img_batch, label_batch = data_batch\n",
        "    img_batch = img_batch.to(device)\n",
        "    _, label_ind = torch.max(label_batch.data, 1)\n",
        "    mixup_pool_OL[label_ind.numpy()[0]].append(img_batch)\n",
        "    if i >= (num_pool - 1):\n",
        "        break\n",
        "\n",
        "print('Finish constructing mixup_pool_OL')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 9959/10000 [00:16<00:00, 689.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finish constructing mixup_pool_OL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W79o71oSrYB8",
        "colab_type": "text"
      },
      "source": [
        "### Construct surrogate models that wrap OL within model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          5
        ],
        "id": "ySaBEdFmrYB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "soft_max = nn.Softmax(dim=-1)\n",
        "\n",
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self, classifier):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.classifier = classifier\n",
        "\n",
        "    def forward(self, img_batch):\n",
        "        pred_cle_mixup_all_OL = 0 # torch.Tensor([0.]*10)\n",
        "        \n",
        "        # forward pass without PL/OL\n",
        "        pred_cle = self.classifier(img_batch)\n",
        "        cle_con, predicted_cle = torch.max(soft_max(pred_cle.data), 1)\n",
        "        predicted_cle = predicted_cle.cpu().numpy()\n",
        "            \n",
        "        # perform MI-OL\n",
        "        for k in range(num_sample_MIOL):\n",
        "            mixup_img_batch = np.empty(img_batch.shape, dtype=np.float32)\n",
        "            \n",
        "            for b in range(img_batch.shape[0]):\n",
        "                # CLEAN\n",
        "                xs_cle_label = np.random.randint(10)\n",
        "                while xs_cle_label == predicted_cle[b]:\n",
        "                    xs_cle_label = np.random.randint(10)\n",
        "                xs_cle_index = np.random.randint(len(mixup_pool_OL[xs_cle_label]))\n",
        "                mixup_img_cle = (1 - lamdaOL) * mixup_pool_OL[xs_cle_label][xs_cle_index][0]\n",
        "                mixup_img_batch[b] = mixup_img_cle.cpu().detach().numpy()\n",
        "\n",
        "            mixup_img_batch = ep.from_numpy(ep.astensor(img_batch), mixup_img_batch).raw + lamdaOL * img_batch\n",
        "            pred_cle_mixup = classifier(mixup_img_batch)\n",
        "            pred_cle_mixup_all_OL = pred_cle_mixup_all_OL + soft_max(pred_cle_mixup)\n",
        "\n",
        "        pred_cle_mixup_all_OL = pred_cle_mixup_all_OL / num_sample_MIOL\n",
        "\n",
        "        return pred_cle_mixup_all_OL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m0rRzwHrYCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_classifier = CombinedModel(classifier)\n",
        "combined_classifier.eval();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bizzUyAtrYCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iAT_model = fb.models.PyTorchModel(classifier, bounds=(-1, 1), device=device)\n",
        "iAT_OL_model = fb.models.PyTorchModel(combined_classifier, bounds=(-1, 1), device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIYW5RTQrYCf",
        "colab_type": "text"
      },
      "source": [
        "### Oblivious attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bf-XmDcrYCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c6b6fdc-c66b-4f67-eda7-c905bfb8d862"
      },
      "source": [
        "acc = 0\n",
        "total_samples = 0\n",
        "\n",
        "for x_batch, y_batch in dataloader_test:\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.argmax(1).to(device)\n",
        "    \n",
        "    acc += fb.utils.accuracy(iAT_OL_model, x_batch, y_batch) * x_batch.shape[0]\n",
        "    total_samples += x_batch.shape[0]\n",
        "\n",
        "print(f'Clean accuracy: {acc / total_samples:.3f}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clean accuracy: 0.825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "h0kuvayFrYCu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f040bba-c5e1-4277-f7ae-2ae5fd97d484"
      },
      "source": [
        "acc = 0\n",
        "total_samples = 0\n",
        "epsilon = 8 / 255\n",
        "\n",
        "attack = fb.attacks.LinfPGD()\n",
        "\n",
        "for images, labels in dataloader_test:\n",
        "    images = images.to(device)\n",
        "    labels = labels.argmax(1).to(device)\n",
        "    N = len(images)\n",
        "    \n",
        "    # PGD returns three values: (1) the raw adversarial images as returned by the\n",
        "    # attack, (2) the raw adversarials clipped to the valid epsilon region and\n",
        "    # (3) a boolean tensor indicating which perturbations are actually adversarial\n",
        "    adv, adv_clipped, adv_mask = attack(iAT_model, images, criterion=fb.criteria.Misclassification(labels), epsilons=2 * epsilon)\n",
        "\n",
        "    acc += fb.utils.accuracy(iAT_OL_model, adv_clipped, labels) * N\n",
        "    total_samples += N\n",
        "    \n",
        "print()\n",
        "print(f'Oblivious adversarial accuracy: {acc / total_samples:.3f}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 9959/10000 [00:29<00:00, 689.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Oblivious adversarial accuracy: 0.655\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}